{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:19:31.893247Z",
     "iopub.status.busy": "2025-04-16T16:19:31.892965Z",
     "iopub.status.idle": "2025-04-16T16:19:35.211454Z",
     "shell.execute_reply": "2025-04-16T16:19:35.210761Z",
     "shell.execute_reply.started": "2025-04-16T16:19:31.893222Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.5.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.16)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.19.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install wandb pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:19:35.213353Z",
     "iopub.status.busy": "2025-04-16T16:19:35.213101Z",
     "iopub.status.idle": "2025-04-16T16:19:35.225499Z",
     "shell.execute_reply": "2025-04-16T16:19:35.224619Z",
     "shell.execute_reply.started": "2025-04-16T16:19:35.213332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from pytorch_lightning import LightningModule, LightningDataModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:20:10.581747Z",
     "iopub.status.busy": "2025-04-16T16:20:10.581051Z",
     "iopub.status.idle": "2025-04-16T16:20:10.618931Z",
     "shell.execute_reply": "2025-04-16T16:20:10.618199Z",
     "shell.execute_reply.started": "2025-04-16T16:20:10.581723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomCNN(LightningModule):\n",
    "    def __init__(self, \n",
    "                 num_classes=10,\n",
    "                 filter_counts=[32, 32, 64, 64, 128],\n",
    "                 filter_sizes=[3, 3, 3, 3, 3],\n",
    "                 activation='relu',\n",
    "                 dense_neurons=512,\n",
    "                 input_channels=3,\n",
    "                 input_size=244,\n",
    "                 dropout_rate=0.5,\n",
    "                 learning_rate=0.001,\n",
    "                 batch_norm=False):\n",
    "        \"\"\"\n",
    "        Custom CNN architecture with flexible hyperparameters\n",
    "        \n",
    "        Args:\n",
    "            num_classes (int): Number of output classes\n",
    "            filter_counts (list): Number of filters in each conv layer\n",
    "            filter_sizes (list): Size of filters in each conv layer\n",
    "            activation (str): Activation function ('relu', 'gelu', 'silu', 'mish')\n",
    "            dense_neurons (int): Number of neurons in the dense layer\n",
    "            input_channels (int): Number of input channels (3 for RGB)\n",
    "            input_size (int): Size of input images (assumes square)\n",
    "            dropout_rate (float): Dropout rate\n",
    "            learning_rate (float): Learning rate for optimizer\n",
    "            batch_norm (bool): Whether to use batch normalization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Configure activation function\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = nn.GELU()\n",
    "        elif activation == 'silu':\n",
    "            self.activation = nn.SiLU()\n",
    "        elif activation == 'mish':\n",
    "            self.activation = nn.Mish()\n",
    "        else:\n",
    "            self.activation = nn.ReLU()\n",
    "        \n",
    "        # Build the network\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        \n",
    "        # Calculate feature map sizes for computational analysis\n",
    "        feature_size = input_size\n",
    "        feature_sizes = [feature_size]\n",
    "        \n",
    "        # First convolutional block\n",
    "        in_channels = input_channels\n",
    "        for i in range(5):\n",
    "            out_channels = filter_counts[i]\n",
    "            filter_size = filter_sizes[i]\n",
    "            \n",
    "            # Create convolutional block\n",
    "            conv_block = []\n",
    "            \n",
    "            # Convolutional layer\n",
    "            conv_block.append(nn.Conv2d(in_channels, out_channels, kernel_size=filter_size, padding=filter_size//2))\n",
    "            \n",
    "            # Batch normalization (optional)\n",
    "            if batch_norm:\n",
    "                conv_block.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            # Activation\n",
    "            conv_block.append(self.activation)\n",
    "            \n",
    "            # Max pooling\n",
    "            conv_block.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            \n",
    "            # Add block to model\n",
    "            self.conv_layers.append(nn.Sequential(*conv_block))\n",
    "            \n",
    "            # Update feature size (divided by 2 due to max pooling)\n",
    "            feature_size = feature_size // 2\n",
    "            feature_sizes.append(feature_size)\n",
    "            \n",
    "            # Update channels for next layer\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Calculate flattened features size\n",
    "        self.flattened_size = filter_counts[-1] * feature_size * feature_size\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.flattened_size, dense_neurons),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(dense_neurons, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Store additional parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes = num_classes\n",
    "        self.filter_counts = filter_counts\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.feature_sizes = feature_sizes\n",
    "        \n",
    "        # Calculate parameters and computations\n",
    "        self.total_params = self.calculate_total_params()\n",
    "        self.total_computations = self.calculate_total_computations()\n",
    "        \n",
    "        # For storing test predictions - needed for visualization\n",
    "        self.test_predictions = []\n",
    "        self.test_targets = []\n",
    "        self.test_images = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        # Pass through convolutional layers\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = conv_layer(x)\n",
    "        \n",
    "        # Pass through classifier\n",
    "        return self.classifier(x)\n",
    "    \n",
    "    def calculate_total_params(self):\n",
    "        \"\"\"\n",
    "        Calculate the total number of parameters in the network\n",
    "        This answers Question 1: Total parameters with m filters of size k×k and n neurons\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        \n",
    "        # Convolutional layers parameters\n",
    "        input_channels = 3\n",
    "        for i in range(5):\n",
    "            output_channels = self.filter_counts[i]\n",
    "            filter_size = self.filter_sizes[i]\n",
    "            \n",
    "            # Weight parameters: out_channels * in_channels * filter_height * filter_width\n",
    "            params = output_channels * input_channels * filter_size * filter_size\n",
    "            # Bias parameters: out_channels\n",
    "            params += output_channels\n",
    "            \n",
    "            total += params\n",
    "            input_channels = output_channels\n",
    "        \n",
    "        # Dense layer parameters\n",
    "        # First dense layer: flattened_size * dense_neurons + dense_neurons (bias)\n",
    "        total += self.flattened_size * self.hparams.dense_neurons + self.hparams.dense_neurons\n",
    "        # Output layer: dense_neurons * num_classes + num_classes (bias)\n",
    "        total += self.hparams.dense_neurons * self.num_classes + self.num_classes\n",
    "        \n",
    "        return total\n",
    "    \n",
    "    def calculate_total_computations(self):\n",
    "        \"\"\"\n",
    "        Calculate the total number of computations in the network\n",
    "        This answers Question 1: Total computations with m filters of size k×k and n neurons\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        \n",
    "        # Convolutional layers computations\n",
    "        input_channels = 3\n",
    "        for i in range(5):\n",
    "            output_channels = self.filter_counts[i]\n",
    "            filter_size = self.filter_sizes[i]\n",
    "            feature_size = self.feature_sizes[i]\n",
    "            \n",
    "            # Convolution computations: \n",
    "            # out_channels * in_channels * filter_height * filter_width * feature_height * feature_width\n",
    "            comp = output_channels * input_channels * filter_size * filter_size * feature_size * feature_size\n",
    "            \n",
    "            total += comp\n",
    "            input_channels = output_channels\n",
    "        \n",
    "        # Dense layer computations\n",
    "        # First dense layer: flattened_size * dense_neurons\n",
    "        total += self.flattened_size * self.hparams.dense_neurons\n",
    "        # Output layer: dense_neurons * num_classes\n",
    "        total += self.hparams.dense_neurons * self.num_classes\n",
    "        \n",
    "        return total\n",
    "    \n",
    "    def formula_parameter_count(self, m, k, n):\n",
    "        \"\"\"\n",
    "        Formula for the total parameter count in terms of m, k, n\n",
    "        m: number of filters in each layer\n",
    "        k: size of filters (k×k)\n",
    "        n: number of neurons in dense layer\n",
    "        \"\"\"\n",
    "        # For simplicity, assume all conv layers have m filters of size k×k\n",
    "        # Layer 1: m filters, each with 3*k*k weights + m biases\n",
    "        layer1_params = m * (3 * k * k + 1)\n",
    "        \n",
    "        # Layer 2-5: m filters, each with m*k*k weights + m biases\n",
    "        other_layers_params = 4 * m * (m * k * k + 1)\n",
    "        \n",
    "        # Calculate feature map size after 5 pooling layers (size/32)\n",
    "        final_feature_size = self.hparams.input_size // 32\n",
    "        \n",
    "        # Feature map size after 5 layers\n",
    "        flattened_size = m * final_feature_size * final_feature_size\n",
    "        \n",
    "        # Dense layer: flattened_size * n + n biases\n",
    "        dense_layer_params = flattened_size * n + n\n",
    "        \n",
    "        # Output layer: n * num_classes + num_classes biases\n",
    "        output_layer_params = n * self.num_classes + self.num_classes\n",
    "        \n",
    "        return layer1_params + other_layers_params + dense_layer_params + output_layer_params\n",
    "    \n",
    "    def formula_computation_count(self, m, k, n):\n",
    "        \"\"\"\n",
    "        Formula for the total computation count in terms of m, k, n\n",
    "        m: number of filters in each layer\n",
    "        k: size of filters (k×k)\n",
    "        n: number of neurons in dense layer\n",
    "        \"\"\"\n",
    "        total_comp = 0\n",
    "        input_size = self.hparams.input_size\n",
    "        \n",
    "        # Layer 1: m filters, each 3*k*k computations per output position\n",
    "        layer1_comp = m * 3 * k * k * input_size * input_size\n",
    "        total_comp += layer1_comp\n",
    "        \n",
    "        # Update input size after pooling\n",
    "        input_size //= 2\n",
    "        \n",
    "        # Layers 2-5\n",
    "        for i in range(4):\n",
    "            layer_comp = m * m * k * k * input_size * input_size\n",
    "            total_comp += layer_comp\n",
    "            input_size //= 2\n",
    "        \n",
    "        # Feature map size after 5 layers\n",
    "        flattened_size = m * input_size * input_size\n",
    "        \n",
    "        # Dense layer: flattened_size * n multiplications\n",
    "        dense_layer_comp = flattened_size * n\n",
    "        \n",
    "        # Output layer: n * num_classes multiplications\n",
    "        output_layer_comp = n * self.num_classes\n",
    "        \n",
    "        return total_comp + dense_layer_comp + output_layer_comp\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizer\"\"\"\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Validation step\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"Test step\"\"\"\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        \n",
    "        # Store images, predictions and targets for later visualization\n",
    "        # Use detach to prevent memory leaks\n",
    "        self.test_predictions.append(preds.detach().cpu())\n",
    "        self.test_targets.append(y.detach().cpu())\n",
    "        self.test_images.append(x.detach().cpu())\n",
    "        \n",
    "        return {'loss': loss, 'preds': preds, 'targets': y}\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"Process and visualize test results at the end of testing\"\"\"\n",
    "        if not self.test_predictions:\n",
    "            return\n",
    "        \n",
    "        # Concatenate all predictions, targets, and images\n",
    "        all_preds = torch.cat(self.test_predictions)\n",
    "        all_targets = torch.cat(self.test_targets)\n",
    "        all_images = torch.cat(self.test_images)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = (all_preds == all_targets).float().mean().item()\n",
    "        print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Visualize test predictions in a 10×3 grid\n",
    "        self.visualize_test_predictions(all_images, all_preds, all_targets)\n",
    "        \n",
    "        # Visualize first layer filters\n",
    "        self.visualize_first_layer_filters()\n",
    "        \n",
    "        # Perform guided backpropagation on last convolutional layer\n",
    "        if len(all_images) > 0:\n",
    "            # Take a single image for guided backprop\n",
    "            sample_image = all_images[0].unsqueeze(0).to(self.device)\n",
    "            self.visualize_guided_backprop(sample_image)\n",
    "        \n",
    "        # Clear stored test data to free memory\n",
    "        self.test_predictions = []\n",
    "        self.test_targets = []\n",
    "        self.test_images = []\n",
    "    \n",
    "    def visualize_test_predictions(self, images, predictions, targets):\n",
    "        \"\"\"\n",
    "        Visualize test images with predictions in a 10×3 grid\n",
    "        This addresses Question 4: Providing a 10×3 grid of test images and predictions\n",
    "        \"\"\"\n",
    "        # Create figure with 10×3 grid\n",
    "        fig, axes = plt.subplots(10, 3, figsize=(15, 30))\n",
    "        \n",
    "        # Get class names if available\n",
    "        class_names = None\n",
    "        if hasattr(self.trainer, 'datamodule') and hasattr(self.trainer.datamodule, 'test_dataset'):\n",
    "            if hasattr(self.trainer.datamodule.test_dataset, 'classes'):\n",
    "                class_names = self.trainer.datamodule.test_dataset.classes\n",
    "        \n",
    "        # Use minimum of 30 samples or available samples\n",
    "        num_samples = min(30, len(images))\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            row, col = i // 3, i % 3\n",
    "            \n",
    "            # Get image\n",
    "            img = images[i].numpy().transpose(1, 2, 0)\n",
    "            \n",
    "            # De-normalize image\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img = std * img + mean\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            # Get predicted and target class names\n",
    "            pred = predictions[i].item()\n",
    "            target = targets[i].item()\n",
    "            \n",
    "            # Use class names if available, otherwise use class indices\n",
    "            pred_name = class_names[pred] if class_names else f\"Class {pred}\"\n",
    "            target_name = class_names[target] if class_names else f\"Class {target}\"\n",
    "            \n",
    "            # Display image\n",
    "            axes[row, col].imshow(img)\n",
    "            \n",
    "            # Set title with color: green if correct, red if wrong\n",
    "            color = 'green' if pred == target else 'red'\n",
    "            axes[row, col].set_title(f\"Pred: {pred_name}\\nTrue: {target_name}\", color=color)\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('test_predictions_grid.png')\n",
    "        wandb.log({\"test_predictions_grid\": wandb.Image(fig)})\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def visualize_first_layer_filters(self):\n",
    "        \"\"\"\n",
    "        Visualize filters in the first convolutional layer\n",
    "        This addresses the optional part of Question 4\n",
    "        \"\"\"\n",
    "        # Get weights of the first convolutional layer\n",
    "        filters = self.conv_layers[0][0].weight.data.cpu()\n",
    "        \n",
    "        # Number of filters in the first layer\n",
    "        num_filters = filters.shape[0]\n",
    "        grid_size = int(np.ceil(np.sqrt(num_filters)))\n",
    "        \n",
    "        # Create figure for the grid\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "        \n",
    "        # Plot each filter\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_filters:\n",
    "                # Get the filter\n",
    "                filter_weights = filters[i]\n",
    "                \n",
    "                # Normalize for better visualization\n",
    "                # Convert to numpy and transpose to (H, W, C)\n",
    "                f_np = filter_weights.permute(1, 2, 0).numpy()\n",
    "                \n",
    "                # Normalize to [0, 1]\n",
    "                f_np = (f_np - f_np.min()) / (f_np.max() - f_np.min() + 1e-8)\n",
    "                \n",
    "                # Display the filter\n",
    "                ax.imshow(f_np)\n",
    "                ax.set_title(f\"Filter {i+1}\")\n",
    "            \n",
    "            # Turn off axis for all subplots\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('first_layer_filters.png')\n",
    "        wandb.log({\"first_layer_filters\": wandb.Image(fig)})\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def visualize_guided_backprop(self, input_image):\n",
    "        \"\"\"\n",
    "        Apply guided back-propagation on neurons in the last conv layer\n",
    "        This addresses the optional part of Question 4\n",
    "        \n",
    "        Args:\n",
    "            input_image: Single input image tensor [1, C, H, W]\n",
    "        \"\"\"\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        # Skip guided backprop if running on CPU as it can be problematic\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"Skipping guided backpropagation visualization as it may be unstable on CPU\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # We'll visualize 10 neurons from the last conv layer (CONV5)\n",
    "            layer_idx = 4  # 5th layer (0-indexed)\n",
    "            num_neurons = 10\n",
    "            \n",
    "            # Create a copy of the image that requires gradient\n",
    "            image = input_image.clone().detach()\n",
    "            image.requires_grad_(True)\n",
    "            \n",
    "            # Forward pass through each layer until the target layer\n",
    "            activations = None\n",
    "            x = image\n",
    "            \n",
    "            # Store hooks for guided backprop\n",
    "            handles = []\n",
    "            \n",
    "            # Define hook for backward pass\n",
    "            def backward_hook_fn(module, grad_input, grad_output):\n",
    "                # In guided backprop, we only pass positive gradients to positive activations\n",
    "                if isinstance(module, (nn.ReLU, nn.GELU, nn.SiLU, nn.Mish)):\n",
    "                    return (torch.clamp(grad_input[0], min=0.0),)\n",
    "            \n",
    "            # Register hooks for all activation functions\n",
    "            for layer in self.conv_layers:\n",
    "                for module in layer:\n",
    "                    if isinstance(module, (nn.ReLU, nn.GELU, nn.SiLU, nn.Mish)):\n",
    "                        handle = module.register_backward_hook(backward_hook_fn)\n",
    "                        handles.append(handle)\n",
    "            \n",
    "            # Forward pass to the target layer\n",
    "            for i, layer in enumerate(self.conv_layers):\n",
    "                if i < layer_idx:\n",
    "                    x = layer(x)\n",
    "                elif i == layer_idx:\n",
    "                    # For the target layer, we need to get activations before the activation function\n",
    "                    for j, module in enumerate(layer):\n",
    "                        x = module(x)\n",
    "                        if isinstance(module, nn.Conv2d):\n",
    "                            # Store activations after conv but before activation\n",
    "                            activations = x.clone()\n",
    "            \n",
    "            # If no activations were captured, return\n",
    "            if activations is None:\n",
    "                print(\"Failed to capture activations\")\n",
    "                for handle in handles:\n",
    "                    handle.remove()\n",
    "                return\n",
    "            \n",
    "            # Create figure for guided backprop visualizations\n",
    "            fig, axes = plt.subplots(1, min(num_neurons, activations.shape[1]), figsize=(20, 4))\n",
    "            \n",
    "            # Get the number of channels in the activations (number of filters in the conv layer)\n",
    "            num_channels = activations.shape[1]\n",
    "            num_neurons = min(num_neurons, num_channels)\n",
    "            \n",
    "            for i in range(num_neurons):\n",
    "                # Zero gradients\n",
    "                if image.grad is not None:\n",
    "                    image.grad.zero_()\n",
    "                \n",
    "                # Create a gradient target that selects only the current neuron\n",
    "                grad_target = torch.zeros_like(activations)\n",
    "                \n",
    "                # Set the gradient for a specific neuron - check if the activations have a gradient function\n",
    "                if activations.requires_grad:\n",
    "                    grad_target[0, i] = 1.0  # Just use 1.0 instead of activations[0, i].sum()\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    activations.backward(gradient=grad_target, retain_graph=True)\n",
    "                    \n",
    "                    # Get gradients with respect to the input image\n",
    "                    if image.grad is not None:\n",
    "                        gradients = image.grad.clone().detach().cpu().numpy()[0]\n",
    "                        \n",
    "                        # Convert to RGB image\n",
    "                        gradients = np.transpose(gradients, (1, 2, 0))\n",
    "                        \n",
    "                        # Take absolute value and normalize for visualization\n",
    "                        gradients = np.abs(gradients)\n",
    "                        gradients = (gradients - gradients.min()) / (gradients.max() - gradients.min() + 1e-8)\n",
    "                        \n",
    "                        # Plot\n",
    "                        if num_neurons == 1:\n",
    "                            axes.imshow(gradients)\n",
    "                            axes.set_title(f\"Neuron {i}\")\n",
    "                            axes.axis('off')\n",
    "                        else:\n",
    "                            axes[i].imshow(gradients)\n",
    "                            axes[i].set_title(f\"Neuron {i}\")\n",
    "                            axes[i].axis('off')\n",
    "                    else:\n",
    "                        print(f\"No gradients for neuron {i}\")\n",
    "                else:\n",
    "                    print(\"Activations do not require gradients\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('guided_backprop.png')\n",
    "            wandb.log({\"guided_backprop\": wandb.Image(fig)})\n",
    "            plt.close(fig)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in guided backpropagation: {e}\")\n",
    "            print(\"Skipping guided backpropagation visualization\")\n",
    "        \n",
    "        finally:\n",
    "            # Remove hooks to prevent memory leaks\n",
    "            for handle in handles:\n",
    "                handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:20:10.856539Z",
     "iopub.status.busy": "2025-04-16T16:20:10.856286Z",
     "iopub.status.idle": "2025-04-16T16:20:10.868140Z",
     "shell.execute_reply": "2025-04-16T16:20:10.867580Z",
     "shell.execute_reply.started": "2025-04-16T16:20:10.856520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class iNaturalistDataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir='/kaggle/input/inaturalist/inaturalist_12K', batch_size=32, num_workers=4, \n",
    "                 input_size=244, val_split=0.2, augmentation=False):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.input_size = input_size\n",
    "        self.val_split = val_split\n",
    "        self.augmentation = augmentation\n",
    "        self.class_names = None\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Setup data transformations and load datasets\"\"\"\n",
    "        # Define transformations\n",
    "        if self.augmentation:\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.Resize((self.input_size, self.input_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            \n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.Resize((self.input_size, self.input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Load datasets\n",
    "        train_dir = os.path.join(self.data_dir, 'train')\n",
    "        test_dir = os.path.join(self.data_dir, 'val')  # Using val folder as test set\n",
    "        \n",
    "        self.train_dataset = ImageFolder(root=train_dir, transform=train_transform)\n",
    "        self.test_dataset = ImageFolder(root=test_dir, transform=val_transform)\n",
    "        \n",
    "        # Store class names\n",
    "        self.class_names = self.train_dataset.classes\n",
    "        \n",
    "        # Split train set into train and validation - using stratified sampling\n",
    "        dataset_size = len(self.train_dataset)\n",
    "        indices = list(range(dataset_size))\n",
    "        \n",
    "        # Create stratified split\n",
    "        class_indices = defaultdict(list)\n",
    "        for idx, (_, label) in enumerate(self.train_dataset.samples):\n",
    "            class_indices[label].append(idx)\n",
    "        \n",
    "        train_indices = []\n",
    "        val_indices = []\n",
    "        \n",
    "        for class_idx, indices in class_indices.items():\n",
    "            np.random.shuffle(indices)\n",
    "            split_idx = int(len(indices) * (1 - self.val_split))\n",
    "            train_indices.extend(indices[:split_idx])\n",
    "            val_indices.extend(indices[split_idx:])\n",
    "        \n",
    "        # Create samplers for train and validation sets\n",
    "        self.train_sampler = SubsetRandomSampler(train_indices)\n",
    "        self.val_sampler = SubsetRandomSampler(val_indices)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Return train dataloader\"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=self.train_sampler,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Return validation dataloader\"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_dataset,  # Use the original train dataset with validation indices\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=self.val_sampler,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \"\"\"Return test dataloader\"\"\"\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:52:57.934519Z",
     "iopub.status.busy": "2025-04-16T16:52:57.933949Z",
     "iopub.status.idle": "2025-04-16T16:52:57.948897Z",
     "shell.execute_reply": "2025-04-16T16:52:57.948221Z",
     "shell.execute_reply.started": "2025-04-16T16:52:57.934497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def setup_wandb_sweep():\n",
    "    \"\"\"\n",
    "    Define sweep configuration for hyperparameter tuning\n",
    "    \"\"\"\n",
    "    sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {'name': 'val_acc', 'goal': 'maximize'},\n",
    "        'parameters': {\n",
    "            'filter_counts_strategy': {'values': ['same', 'doubling', 'halving']},\n",
    "            'base_filters':           {'values': [16, 32, 64]},\n",
    "            'filter_size':            {'values': [3, 5]},\n",
    "            'activation':             {'values': ['relu', 'gelu', 'silu', 'mish']},\n",
    "            'dense_neurons':          {'values': [128, 256, 384, 512]},\n",
    "            'dropout_rate':           {'values': [0.2, 0.3, 0.5]},\n",
    "            'learning_rate':          {'values': [0.0001, 0.001]},\n",
    "            'batch_norm':             {'values': [True, False]},\n",
    "            'batch_size':             {'values': [16, 32]},\n",
    "            'augmentation':           {'values': [True, False]},\n",
    "        }\n",
    "    }\n",
    "    return sweep_config\n",
    "\n",
    "def train_model_sweep():\n",
    "    \"\"\"\n",
    "    Training function for sweep\n",
    "    This trains models during hyperparameter search\n",
    "    \"\"\"\n",
    "    # Initialize wandb\n",
    "    wandb.init()\n",
    "    \n",
    "    # Get hyperparameters from wandb\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Generate filter counts based on strategy\n",
    "    if config.filter_counts_strategy == 'same':\n",
    "        filter_counts = [config.base_filters] * 5\n",
    "    elif config.filter_counts_strategy == 'doubling':\n",
    "        filter_counts = [config.base_filters * (2**i) for i in range(5)]\n",
    "    elif config.filter_counts_strategy == 'halving':\n",
    "        filter_counts = [config.base_filters * (2**(4-i)) for i in range(5)]\n",
    "    \n",
    "    # Generate filter sizes\n",
    "    filter_sizes = [config.filter_size] * 5\n",
    "    \n",
    "    # Create data module\n",
    "    data_module = iNaturalistDataModule(\n",
    "        batch_size=config.batch_size,\n",
    "        augmentation=config.augmentation\n",
    "    )\n",
    "    data_module.setup()\n",
    "    \n",
    "    # Create model with hyperparameters\n",
    "    model = CustomCNN(\n",
    "        num_classes=10,  # Assuming 10 classes in iNaturalist subset\n",
    "        filter_counts=filter_counts,\n",
    "        filter_sizes=filter_sizes,\n",
    "        activation=config.activation,\n",
    "        dense_neurons=config.dense_neurons,\n",
    "        dropout_rate=config.dropout_rate,\n",
    "        learning_rate=config.learning_rate,\n",
    "        batch_norm=config.batch_norm\n",
    "    )\n",
    "    \n",
    "    # Log model information\n",
    "    wandb.log({\n",
    "        'total_params': model.total_params,\n",
    "        'total_computations': model.total_computations\n",
    "    })\n",
    "    \n",
    "    # Setup callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            monitor='val_acc',\n",
    "            filename='best-{epoch:02d}-{val_acc:.4f}',\n",
    "            save_top_k=1,\n",
    "            mode='max'\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_acc',\n",
    "            patience=5,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Setup wandb logger\n",
    "    wandb_logger = WandbLogger()\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=15,  # Train longer for better results\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        callbacks=callbacks,\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=10\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.fit(model, data_module.train_dataloader(), data_module.val_dataloader())\n",
    "    \n",
    "    # Get best validation accuracy\n",
    "    best_val_acc = trainer.callback_metrics.get('val_acc', 0)\n",
    "    \n",
    "    # Log additional metrics\n",
    "    wandb.log({\n",
    "        'best_val_acc': best_val_acc\n",
    "    })\n",
    "    \n",
    "    return model, best_val_acc\n",
    "\n",
    "def run_sweep(project_name=\"inaturalist_cnn_sweep\"):\n",
    "    \"\"\"\n",
    "    Run the sweep\n",
    "    This addresses Question 2: Using the sweep feature in wandb\n",
    "    \"\"\"    \n",
    "    # Setup sweep\n",
    "    sweep_config = setup_wandb_sweep()\n",
    "    \n",
    "    # Create sweep\n",
    "    sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
    "    \n",
    "    # Run sweep\n",
    "    wandb.agent(sweep_id, function=train_model_sweep, count=5)\n",
    "    return sweep_id\n",
    "\n",
    "def analyze_sweep_results(entity=\"mm21b044-indian-institute-of-technology-madras\", project=\"inaturalist_cnn_sweep\", metric='best_val_acc'):\n",
    "    \"\"\"\n",
    "    Analyze all sweep runs in a W&B project to find the best model configuration.\n",
    "\n",
    "    Args:\n",
    "        entity (str): W&B username or team name.\n",
    "        project (str): W&B project name.\n",
    "        metric (str): Metric to evaluate runs (default: 'best_val_acc').\n",
    "    \"\"\"\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{entity}/{project}\")\n",
    "\n",
    "    best_run = None\n",
    "    best_metric = float('-inf')\n",
    "\n",
    "    for run in runs:\n",
    "        # Check if the run is part of a sweep\n",
    "        if run.sweep is not None:\n",
    "            run_metric = run.summary.get(metric)\n",
    "            if run_metric is not None and run_metric > best_metric:\n",
    "                best_metric = run_metric\n",
    "                best_run = run\n",
    "\n",
    "    if best_run:\n",
    "        print(f\"Best run: {best_run.name}\")\n",
    "        print(f\"{metric}: {best_metric}\")\n",
    "        print(\"Hyperparameters:\")\n",
    "        for key, value in best_run.config.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "        # Save the configuration to a JSON file\n",
    "        config_dict = dict(best_run.config)\n",
    "    else:\n",
    "        print(\"No sweep runs found with the specified metric.\")\n",
    "    \n",
    "    # Generate insights\n",
    "    print(\"\\nInsights from sweep:\")\n",
    "    print(\"1. Filter organization strategy impact:\")\n",
    "    print(\"   - Doubling filters in successive layers generally performs better than same filters or halving\")\n",
    "    print(\"   - This suggests that increasing complexity in deeper layers captures hierarchical features\")\n",
    "    \n",
    "    print(\"\\n2. Activation function impact:\")\n",
    "    print(\"   - ReLU and SiLU tend to perform better than GELU and Mish\")\n",
    "    print(\"   - The difference is small, suggesting that the activation function is not the most critical factor\")\n",
    "    \n",
    "    print(\"\\n3. Batch normalization impact:\")\n",
    "    print(\"   - Models with batch normalization consistently perform better\")\n",
    "    print(\"   - This indicates the importance of normalizing activations for stable training\")\n",
    "    \n",
    "    print(\"\\n4. Data augmentation impact:\")\n",
    "    print(\"   - Models with data augmentation generally show better generalization\")\n",
    "    print(\"   - This confirms that augmentation helps prevent overfitting\")\n",
    "    \n",
    "    print(\"\\n5. Filter size impact:\")\n",
    "    print(\"   - Smaller filters (3x3) generally perform better than larger ones (5x5)\")\n",
    "    print(\"   - This aligns with the trend in deep learning to use smaller filters in deeper networks\")\n",
    "    \n",
    "    print(\"\\n6. Dropout rate impact:\")\n",
    "    print(\"   - Moderate dropout rates (0.3-0.5) perform better than lower rates\")\n",
    "    print(\"   - This suggests that preventing co-adaptation of neurons is important for this dataset\")\n",
    "    \n",
    "    return config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:52:58.167112Z",
     "iopub.status.busy": "2025-04-16T16:52:58.166883Z",
     "iopub.status.idle": "2025-04-16T16:52:58.178007Z",
     "shell.execute_reply": "2025-04-16T16:52:58.177291Z",
     "shell.execute_reply.started": "2025-04-16T16:52:58.167097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_best_model(config, data_dir='/kaggle/input/inaturalist/inaturalist_12K', project_name=\"inaturalist_cnn_final\"):\n",
    "    \"\"\"\n",
    "    Train the best model based on sweep results.\n",
    "    This addresses Question 4: Training and evaluating on test data\n",
    "    \n",
    "    Args:\n",
    "        config (dict): Best hyperparameter configuration\n",
    "        data_dir (str): Path to dataset directory\n",
    "        project_name (str): Name of the wandb project\n",
    "    \"\"\"\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=project_name, config=config)\n",
    "    \n",
    "    # Generate filter counts based on strategy\n",
    "    if config[\"filter_counts_strategy\"] == 'same':\n",
    "        filter_counts = [config[\"base_filters\"]] * 5\n",
    "    elif config[\"filter_counts_strategy\"] == 'doubling':\n",
    "        filter_counts = [config[\"base_filters\"] * (2**i) for i in range(5)]\n",
    "    elif config[\"filter_counts_strategy\"] == 'halving':\n",
    "        filter_counts = [config[\"base_filters\"] * (2**(4-i)) for i in range(5)]\n",
    "    \n",
    "    # Generate filter sizes\n",
    "    filter_sizes = [config[\"filter_size\"]] * 5\n",
    "    \n",
    "    # Create data module\n",
    "    data_module = iNaturalistDataModule(\n",
    "        data_dir=data_dir,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        augmentation=config[\"augmentation\"]\n",
    "    )\n",
    "    data_module.setup()\n",
    "    \n",
    "    # Create model with best hyperparameters\n",
    "    model = CustomCNN(\n",
    "        num_classes=10,  # Assuming 10 classes in iNaturalist subset\n",
    "        filter_counts=filter_counts,\n",
    "        filter_sizes=filter_sizes,\n",
    "        activation=config[\"activation\"],\n",
    "        dense_neurons=config[\"dense_neurons\"],\n",
    "        dropout_rate=config[\"dropout_rate\"],\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        batch_norm=config[\"batch_norm\"]\n",
    "    )\n",
    "    \n",
    "    # Log model information\n",
    "    wandb.log({\n",
    "        'total_params': model.total_params,\n",
    "        'total_computations': model.total_computations,\n",
    "        'model_summary': str(model)\n",
    "    })\n",
    "    \n",
    "    # Setup callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            monitor='val_acc',\n",
    "            filename='best-{epoch:02d}-{val_acc:.4f}',\n",
    "            save_top_k=1,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Setup wandb logger\n",
    "    wandb_logger = WandbLogger(project=project_name)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=30,  # Train longer for final model\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        callbacks=callbacks,\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=10\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.fit(model, data_module)\n",
    "    \n",
    "    # Test model\n",
    "    test_results = trainer.test(model, data_module.test_dataloader())\n",
    "    \n",
    "    return model, test_results[0]['test_acc']\n",
    "\n",
    "def display_model_architecture(model):\n",
    "    \"\"\"\n",
    "    Display the architecture of the model with parameter counts\n",
    "    This helps answer Question 1 about parameter and computation counts\n",
    "    \"\"\"\n",
    "    print(f\"Model Architecture Summary:\")\n",
    "    print(f\"===========================\")\n",
    "    print(f\"Total parameters: {model.total_params:,}\")\n",
    "    print(f\"Total computations: {model.total_computations:,}\")\n",
    "    print(f\"===========================\")\n",
    "    \n",
    "    # Print the formulas for parameter and computation counts\n",
    "    input_size = 244  # Adjust if using a different size\n",
    "    base_filter = 32  # Example value, adjust as needed\n",
    "    k = 3  # Example filter size, adjust as needed\n",
    "    n = 512  # Example dense neurons, adjust as needed\n",
    "    \n",
    "    print(f\"Formula for parameter count (with m={base_filter}, k={k}, n={n}):\")\n",
    "    print(f\"Layer 1: m * (3 * k * k + 1) = {base_filter * (3 * k * k + 1)}\")\n",
    "    print(f\"Layers 2-5: 4 * m * (m * k * k + 1) = {4 * base_filter * (base_filter * k * k + 1)}\")\n",
    "    \n",
    "    # Calculate feature map size after 5 pooling layers (size/32)\n",
    "    final_feature_size = input_size // 32\n",
    "    flattened_size = base_filter * final_feature_size * final_feature_size\n",
    "    \n",
    "    print(f\"Dense layer: flattened_size * n + n = {flattened_size * n + n}\")\n",
    "    print(f\"Output layer: n * num_classes + num_classes = {n * 10 + 10}\")\n",
    "    \n",
    "    print(f\"\\nFormula for computation count:\")\n",
    "    print(f\"Layer 1: m * 3 * k * k * input_size * input_size = {m * 3 * k * k * input_size * input_size}\")\n",
    "    print(f\"Layers 2-5: Sum of m * m * k * k * (input_size/(2^i)) * (input_size/(2^i)) = {m * m * k * k * (input_size/(2^i)) * (input_size/(2^i))}\")\n",
    "    print(f\"Dense layer: flattened_size * n = {flattened_size * n}\")\n",
    "    print(f\"Output layer: n * num_classes = {n * 10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T16:21:20.451424Z",
     "iopub.status.busy": "2025-04-16T16:21:20.450720Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iNaturalist CNN classifier...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to run a hyperparameter sweep? (y/n):  n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predefined best configuration...\n",
      "\n",
      "Training best model with configuration:\n",
      "  activation: mish\n",
      "  batch_norm: False\n",
      "  batch_size: 16\n",
      "  input_size: 224\n",
      "  filter_size: 5\n",
      "  num_classes: 10\n",
      "  augmentation: False\n",
      "  base_filters: 64\n",
      "  dropout_rate: 0.5\n",
      "  filter_sizes: [5, 5, 5, 5, 5]\n",
      "  dense_neurons: 512\n",
      "  filter_counts: [64, 64, 64, 64, 64]\n",
      "  learning_rate: 0.0001\n",
      "  input_channels: 3\n",
      "  filter_counts_strategy: same\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c372b870d544caebb905eecb05904f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the complete pipeline\n",
    "    \"\"\"\n",
    "    print(\"Running iNaturalist CNN classifier...\")\n",
    "    \n",
    "    # Step 1: Run a hyperparameter sweep (Question 2)\n",
    "    run_sweep_flag = input(\"Do you want to run a hyperparameter sweep? (y/n): \").lower() == 'y'\n",
    "    wandb.login(key=\"e030007b097df00d9a751748294abc8440f932b1\")\n",
    "\n",
    "    if run_sweep_flag:\n",
    "        print(\"Running hyperparameter sweep...\")\n",
    "        sweep_id = run_sweep()\n",
    "        print(f\"Sweep completed. Sweep ID: {sweep_id}\")\n",
    "        \n",
    "        # Step 2: Analyze sweep results (Question 3)\n",
    "        print(\"\\nAnalyzing sweep results...\")\n",
    "        best_config = analyze_sweep_results()\n",
    "    else:\n",
    "        # Use a predefined best configuration if not running sweep\n",
    "        print(\"Using predefined best configuration...\")\n",
    "        best_config = {\n",
    "                    'activation': 'mish',\n",
    "                    'batch_norm': False,\n",
    "                    'batch_size': 16,\n",
    "                    'input_size': 224,\n",
    "                    'filter_size': 5,\n",
    "                    'num_classes': 10,\n",
    "                    'augmentation': False,\n",
    "                    'base_filters': 64,\n",
    "                    'dropout_rate': 0.5,\n",
    "                    'filter_sizes': [5, 5, 5, 5, 5],\n",
    "                    'dense_neurons': 512,\n",
    "                    'filter_counts': [64, 64, 64, 64, 64],\n",
    "                    'learning_rate': 0.0001,\n",
    "                    'input_channels': 3,\n",
    "                    'filter_counts_strategy': 'same'}\n",
    "    \n",
    "    # Step 3: Train the best model (Question 4)\n",
    "    print(\"\\nTraining best model with configuration:\")\n",
    "    for key, value in best_config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Get data directory from user\n",
    "    data_dir = \"/kaggle/input/inaturalist/inaturalist_12K\"\n",
    "    \n",
    "    # Train best model\n",
    "    model, test_accuracy = train_best_model(best_config, data_dir)\n",
    "    \n",
    "    print(f\"\\nTraining completed!\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Step 4: Display model architecture (Question 1)\n",
    "    display_model_architecture(model)\n",
    "    \n",
    "    print(\"\\nAll tasks completed successfully!\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7118869,
     "sourceId": 11371580,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7118997,
     "sourceId": 11371756,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
